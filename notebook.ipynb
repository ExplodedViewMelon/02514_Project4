{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task\n",
    "Your tasks for training and deploying a simple object detector to detect litter and trash are:\n",
    "1. Extract object proposals for all the images of the dataset (e.g. Selecting Search, Edge Boxes, etc). Note that you may have to resize the images before you run SS for better efficiency.\n",
    "2. Finetune a convolutional neural network to classify object proposals.\n",
    "3. Apply the model on the test images and implement non-maximum sup- presion and Intersection over Union (IoU).\n",
    "4. Evaluate the object detection performance using standard metrics.\n",
    "Optional tasks:\n",
    "1. Improve the simple model above by adding a bounding-box regression output that improves the detection performance.\n",
    "2. Improve the efficiency of the simple model (i.e., ROI pooling layer inspired by Fast RCNN).\n",
    "3. Implement a Convolutional Neural Network that is trained to generate generic object proposals to replace the object proposal algorithm (i.e., Region Proposal Network inspired by Faster RCNN).\n",
    "The goal of the project is not to simply apply an object detection model that you find online, but rather to build step-by-step a simple model by yourself. After that, feel free to improve this model by following the suggestions in the optional tasks above or to even apply a single-stage object detector."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: ‘demo.ipynb’ and ‘./demo.ipynb’ are the same file\n"
     ]
    }
   ],
   "source": [
    "# DRIVE dataset\n",
    "!( \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd ..; \\\n",
    "cd dtu; \\\n",
    "cd datasets1; \\\n",
    "cd 02514; \\\n",
    "cp -r demo.ipynb .; \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash script to copy \"demo.ipynb\" into current directory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
